# Applying Reinforcement Learning To Infinite-Play And Random Environments: Exploring Optimal Performance In Flappy Bird Through Varying Q-Learning Algorithms

<div style="text-align: center">
Aadarsh Jha <br>
CS 5891: Reinforcement Learning <br>
December 10th, 2021
</div>

## Instructions On Running: 

Please follow the below instructions to see how both trials of the experiments are run, with respect to Deep Q-Learning and Q-Learning.

* First, `git clone https://github.com/aadarshjha/flappy.git` or download this repository from the above link.

* Then, `cd flappy/` and follow the below instructions to run the experiments.

### Deep Q-Learning

* To execute testing and training of the Deep Q-Learning pipeline, `cd` to the `deep-q-learning` directory. 
* Open the `deep-q-learning.ipynb`, instructions are provided in the notebook itself so as to get you started. 
* Note that models are provided from the best performing trial, more are available at request. Please email me: aadarsh.jha@vanderbilt.edu

### Q-Learning
* To execute testing and training of the Deep Q-Learning pipeline, `cd` to the `q-learning` directory. 
* Open the `q-learning.ipynb`, instructions are provided in the notebook itself so as to get you started. 
* Note that models are provided from the best performing trial, more are available at request. Please email me: aadarsh.jha@vanderbilt.edu

### Figures
* Due to the number of charts in the paper, some figures may be hard to read. `cd figures/` to find high resolutoin `.pdf` files that are the figures. 

### References
* As stated in the paper the following repos are drawn inspriation from to execute the Deep Q-Learning and Q-Learning experiments:
    1. Deep Q-Learning: https://github.com/yenchenlin/DeepLearningFlappyBird
    2. Q-Learning: https://github.com/yashkotadia/FlapPy-Bird-RL-Q-Learning-Bot
    3. Enviornment: https://github.com/sourabhv/FlapPyBird